from enveditor import *
import math

# === Pitch-shift helper: compute input index for given output index and semitone shift ===
def get_shifted_index(out_idx, semitone_shift):
    # Semitone shift can be positive or negative
    ratio = 2 ** (semitone_shift / 12.0)
    # Avoid division by zero if ratio is extremely small
    if ratio <= 1e-12:
        return -1  # out of range → implicit silence
    return int(math.floor(out_idx / ratio))

# === Main Stack processing ===
def process_stack(transpose, lean, propn, attack_offset, count, gain):
    # 1) Determine selection range
    x1 = Editor.SelectionStartS
    x2 = Editor.SelectionEndS
    if x2 <= x1:
        x1 = 0
        x2 = EditorSample.Length - 1
    length = x2 - x1 + 1
    sample_rate = EditorSample.SampleRate

    # 2) Compute attack-time offset in samples (clamped to length−1)
    offset_samples = min(int(round(attack_offset * sample_rate)), length - 1)

    # 3) Base segment (starting after attack offset)
    base_start  = x1 + offset_samples
    base_length = length - offset_samples
    if base_length <= 0:
        return  # nothing to process

    # 4) Compute maximum stretched length across all voices (centered stacking)
    center = (count - 1) / 2.0
    max_stretch = 0.0
    for v in range(count):
        semitone_shift = (v - center) * transpose
        ratio = 2 ** (semitone_shift / 12.0)
        stretched = base_length * abs(ratio)
        if stretched > max_stretch:
            max_stretch = stretched
    max_length = int(math.ceil(max_stretch))

    # 5) Apply PROPN (0…1) to this maximum length
    out_length = max(1, int(round(max_length * propn)))

    # 6) If output length exceeds current segment length, extend sample length
    if out_length > length:
        new_length = x1 + out_length
        EditorSample.Length = new_length

    # 7) Read original segment into nested list: original[c][i]
    original = [
        [EditorSample.GetSampleAt(base_start + i, c) for i in range(base_length)]
        for c in range(EditorSample.NumChans)
    ]

    # 8) Prepare accumulation buffer for stacked result
    stacked = [[0.0 for _ in range(out_length)] for _ in range(EditorSample.NumChans)]

    # 9) Sum each voice with pitch shift and LEAN weighting
    for v in range(count):
        semitone_shift = (v - center) * transpose
        if count > 1:
            amp = lean ** (v / (count - 1))
        else:
            amp = 1.0

        for i in range(out_length):
            in_idx = get_shifted_index(i, semitone_shift)
            if 0 <= in_idx < base_length:
                for c in range(EditorSample.NumChans):
                    stacked[c][i] += original[c][in_idx] * amp
        Utils.ProgressMsg(f"Stacking voice {v+1}/{count}", v + 1, count)

    # 10) Normalize by total LEAN mass
    total_amp = 0.0
    for v in range(count):
        if count > 1:
            total_amp += lean ** (v / (count - 1))
        else:
            total_amp += 1.0
    if total_amp <= 0.0:
        total_amp = 1.0

    # 11) Write result back to buffer
    for i in range(out_length):
        for c in range(EditorSample.NumChans):
            val = (stacked[c][i] / total_amp) * gain
            EditorSample.SetSampleAt(x1 + i, c, val)

    # 12) Zero out any remaining samples up to original length (avoid leftover noise)
    for i in range(x1 + out_length, x1 + length):
        for c in range(EditorSample.NumChans):
            EditorSample.SetSampleAt(i, c, 0.0)

# === Interface ===
form = ScriptDialog(
    "Stack",
    "Superimpose transposed copies of the selected audio. Inspired by SoundShaper 6.\n\n"
    "TRANSPOSE: size of interval (semitones) between stacked voices (–60…+60).\n"
    "LEAN: loudness ratio of highest voice to lowest (0.01…100).\n"
    "PROPN: proportion of final stacked length to preserve (0…1).\n"
    "ATTACK-TIME: offset (seconds) into original before stacking (0…27.861).\n"
    "COUNT: number of stacked voices (2…32).\n"
    "GAIN: overall output gain (0.1…10).\n\n"
    "Made by D. Stativkin with ChatGPT. GitHub - emptyjp"
)

form.AddInputKnob("TRANSPOSE",    0.0,  -60.0,  60.0)    # semitones
form.AddInputKnob("LEAN",         1.0,    0.01, 100.0)   # ratio
form.AddInputKnob("PROPN",        1.0,    0.0,   1.0)    # proportion 0..1
form.AddInputKnob("ATTACK-TIME",  0.0,    0.0,   27.861) # seconds
form.AddInputKnob("COUNT",        2.0,    2.0,   32.0)   # voices
form.AddInputKnob("GAIN",         1.0,    0.1,   10.0)   # output gain

if form.Execute():
    transpose    = form.GetInputValue("TRANSPOSE")
    lean         = form.GetInputValue("LEAN")
    propn        = form.GetInputValue("PROPN")
    attack_time  = form.GetInputValue("ATTACK-TIME")
    count        = int(form.GetInputValue("COUNT"))
    gain         = form.GetInputValue("GAIN")

    process_stack(transpose, lean, propn, attack_time, count, gain)
